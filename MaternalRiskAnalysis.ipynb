{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "***Classification Empirical Study - Naïve Bayes vs Logistic Regression***"
      ],
      "metadata": {
        "id": "huBQKZ6vmLcX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Introduction**\n",
        "\n",
        "The dataset that we are going to explore is the following:\n",
        "\n",
        "Maternal Health Risk:\n",
        "\n",
        "> https://archive.ics.uci.edu/dataset/863/maternal+health+risk <br/> Number of samples: 1013, Number of attributes: 6, Number of classes: 3 (risk level – high, medium, low)\n",
        "\n",
        "The goal of this task is to build a classification model that is to predict the <i>Risk Intensity </i>Level during pregnancy considering various attributes such as:\n",
        "- Age\n",
        "- Systolic bloop pressure\n",
        "- Diastolic bloop pressure\n",
        "- Blood glucose levels\n",
        "- Body temperature\n",
        "- Heart rate\n",
        "\n",
        "There are 1013 training samples in total, 6 features (as listed above), in both integer and real number type, and no missing data is reported.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZnefzaIiUjej"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature engineering**\n",
        "\n",
        "The features presented in the dataset seems to be a decent set of attributes to classify As we are not expert in the field, we assume that the features are a good representation and separation of different cases. Ideally a domain expert should be consulted, however this is skipped due to lack of time."
      ],
      "metadata": {
        "id": "WxIHp8aSao_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import itertools\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "1rY-xYPNbmPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://raw.githubusercontent.com/jsong060/csi4106asg2/main/Maternal_Health_Risk_Data_Set.csv'\n",
        "\n",
        "df = pd.read_csv(url)"
      ],
      "metadata": {
        "id": "9yTQk90_c8aT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "dacZeAkHdYsa",
        "outputId": "72e0ecad-9fbf-487a-b413-ff13c3e4b573"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Age  SystolicBP  DiastolicBP    BS  BodyTemp  HeartRate  RiskLevel\n",
              "0   25         130           80  15.0      98.0         86  high risk\n",
              "1   35         140           90  13.0      98.0         70  high risk\n",
              "2   29          90           70   8.0     100.0         80  high risk\n",
              "3   30         140           85   7.0      98.0         70  high risk\n",
              "4   35         120           60   6.1      98.0         76   low risk"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-764b81ac-7fbf-4532-b496-f0e0d76d88b4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>SystolicBP</th>\n",
              "      <th>DiastolicBP</th>\n",
              "      <th>BS</th>\n",
              "      <th>BodyTemp</th>\n",
              "      <th>HeartRate</th>\n",
              "      <th>RiskLevel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>25</td>\n",
              "      <td>130</td>\n",
              "      <td>80</td>\n",
              "      <td>15.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>86</td>\n",
              "      <td>high risk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>35</td>\n",
              "      <td>140</td>\n",
              "      <td>90</td>\n",
              "      <td>13.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>70</td>\n",
              "      <td>high risk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>29</td>\n",
              "      <td>90</td>\n",
              "      <td>70</td>\n",
              "      <td>8.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>80</td>\n",
              "      <td>high risk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>30</td>\n",
              "      <td>140</td>\n",
              "      <td>85</td>\n",
              "      <td>7.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>70</td>\n",
              "      <td>high risk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>35</td>\n",
              "      <td>120</td>\n",
              "      <td>60</td>\n",
              "      <td>6.1</td>\n",
              "      <td>98.0</td>\n",
              "      <td>76</td>\n",
              "      <td>low risk</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-764b81ac-7fbf-4532-b496-f0e0d76d88b4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-764b81ac-7fbf-4532-b496-f0e0d76d88b4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-764b81ac-7fbf-4532-b496-f0e0d76d88b4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-025b5e94-5c32-4b9f-afa4-1351f1ca5f04\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-025b5e94-5c32-4b9f-afa4-1351f1ca5f04')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-025b5e94-5c32-4b9f-afa4-1351f1ca5f04 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape\n",
        "df.columns\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQ3UI3lNK5sQ",
        "outputId": "e1d3e2d4-ff11-411e-a863-05132cdb766e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1014 entries, 0 to 1013\n",
            "Data columns (total 7 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   Age          1014 non-null   int64  \n",
            " 1   SystolicBP   1014 non-null   int64  \n",
            " 2   DiastolicBP  1014 non-null   int64  \n",
            " 3   BS           1014 non-null   float64\n",
            " 4   BodyTemp     1014 non-null   float64\n",
            " 5   HeartRate    1014 non-null   int64  \n",
            " 6   RiskLevel    1014 non-null   object \n",
            "dtypes: float64(2), int64(4), object(1)\n",
            "memory usage: 55.6+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Many machine learning algorithm do not integreate well categorical data. Hence there is a need to transform these types of data into integer representation.This As we can see from the info above, most data we are working with are already in the desired format (int or float). However the target column 'RiskLevel' is in String, we will need to encode and convert them into integers using the one-hot encoding technique."
      ],
      "metadata": {
        "id": "thOdjt6rUI4E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.countplot(data=df,x='Age',hue='RiskLevel')\n",
        "plt.xticks(rotation=90, ha='right');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "dHx_Zlq9gyYY",
        "outputId": "f9f59d8c-edb0-40a5-c11a-958751a683c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also observe that the provided data is not too skewed and is relatively representative of the target population for this specific case study.  "
      ],
      "metadata": {
        "id": "Vo1k-JgOKKFZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pre_df = pd.get_dummies(df,columns=['RiskLevel'])\n",
        "df2 = pre_df.rename({'RiskLevel_high risk': 'RiskLevel_high', 'RiskLevel_low risk': 'RiskLevel_low', 'RiskLevel_mid risk': 'RiskLevel_mid'}, axis='columns')\n",
        "df2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "X09Lwz6dhsnu",
        "outputId": "6a8b3f5e-b0f5-444c-85b1-f2b5cfd04065"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Age  SystolicBP  DiastolicBP    BS  BodyTemp  HeartRate  RiskLevel_high  \\\n",
              "0      25         130           80  15.0      98.0         86               1   \n",
              "1      35         140           90  13.0      98.0         70               1   \n",
              "2      29          90           70   8.0     100.0         80               1   \n",
              "3      30         140           85   7.0      98.0         70               1   \n",
              "4      35         120           60   6.1      98.0         76               0   \n",
              "...   ...         ...          ...   ...       ...        ...             ...   \n",
              "1009   22         120           60  15.0      98.0         80               1   \n",
              "1010   55         120           90  18.0      98.0         60               1   \n",
              "1011   35          85           60  19.0      98.0         86               1   \n",
              "1012   43         120           90  18.0      98.0         70               1   \n",
              "1013   32         120           65   6.0     101.0         76               0   \n",
              "\n",
              "      RiskLevel_low  RiskLevel_mid  \n",
              "0                 0              0  \n",
              "1                 0              0  \n",
              "2                 0              0  \n",
              "3                 0              0  \n",
              "4                 1              0  \n",
              "...             ...            ...  \n",
              "1009              0              0  \n",
              "1010              0              0  \n",
              "1011              0              0  \n",
              "1012              0              0  \n",
              "1013              0              1  \n",
              "\n",
              "[1014 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-216cef89-e720-40d8-b0b9-a03096fd49cb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>SystolicBP</th>\n",
              "      <th>DiastolicBP</th>\n",
              "      <th>BS</th>\n",
              "      <th>BodyTemp</th>\n",
              "      <th>HeartRate</th>\n",
              "      <th>RiskLevel_high</th>\n",
              "      <th>RiskLevel_low</th>\n",
              "      <th>RiskLevel_mid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>25</td>\n",
              "      <td>130</td>\n",
              "      <td>80</td>\n",
              "      <td>15.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>35</td>\n",
              "      <td>140</td>\n",
              "      <td>90</td>\n",
              "      <td>13.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>29</td>\n",
              "      <td>90</td>\n",
              "      <td>70</td>\n",
              "      <td>8.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>30</td>\n",
              "      <td>140</td>\n",
              "      <td>85</td>\n",
              "      <td>7.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>35</td>\n",
              "      <td>120</td>\n",
              "      <td>60</td>\n",
              "      <td>6.1</td>\n",
              "      <td>98.0</td>\n",
              "      <td>76</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1009</th>\n",
              "      <td>22</td>\n",
              "      <td>120</td>\n",
              "      <td>60</td>\n",
              "      <td>15.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>80</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1010</th>\n",
              "      <td>55</td>\n",
              "      <td>120</td>\n",
              "      <td>90</td>\n",
              "      <td>18.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>60</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1011</th>\n",
              "      <td>35</td>\n",
              "      <td>85</td>\n",
              "      <td>60</td>\n",
              "      <td>19.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1012</th>\n",
              "      <td>43</td>\n",
              "      <td>120</td>\n",
              "      <td>90</td>\n",
              "      <td>18.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1013</th>\n",
              "      <td>32</td>\n",
              "      <td>120</td>\n",
              "      <td>65</td>\n",
              "      <td>6.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>76</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1014 rows × 9 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-216cef89-e720-40d8-b0b9-a03096fd49cb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-216cef89-e720-40d8-b0b9-a03096fd49cb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-216cef89-e720-40d8-b0b9-a03096fd49cb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8d1fe875-5073-4cb7-8850-35c2dd05723a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8d1fe875-5073-4cb7-8850-35c2dd05723a')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8d1fe875-5073-4cb7-8850-35c2dd05723a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As shown in the table above, now the target is one-hot encoded, we can now start training our models to predict the risk levels"
      ],
      "metadata": {
        "id": "MyBY_tGLg6nf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data analysis**\n",
        "\n",
        "For this study, we will try to predict the target using 2 sets of models\n",
        "- Naive Bayes\n",
        "- Logistic Regression\n"
      ],
      "metadata": {
        "id": "WBphK2kHhKRz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the data\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "\n",
        "X = df2.drop(['RiskLevel_high', 'RiskLevel_low', 'RiskLevel_mid'], axis=1)\n",
        "y_h, y_l, y_m = df2['RiskLevel_high'], df2['RiskLevel_low'], df2['RiskLevel_mid']\n",
        "\n",
        "X_train_h, X_test_h, y_train_h, y_test_h = train_test_split(\n",
        "    X, y_h, test_size=0.2\n",
        ")\n",
        "\n",
        "X_train_l, X_test_l, y_train_l, y_test_l = train_test_split(\n",
        "    X, y_l, test_size=0.2\n",
        ")\n",
        "\n",
        "X_train_m, X_test_m, y_train_m, y_test_m = train_test_split(\n",
        "    X, y_m, test_size=0.2\n",
        ")"
      ],
      "metadata": {
        "id": "SFf45WfP4tIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data analysis using Naive Bayes**"
      ],
      "metadata": {
        "id": "JNW7xVFpUcRp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    confusion_matrix,\n",
        "    ConfusionMatrixDisplay,\n",
        "    f1_score,\n",
        "    classification_report,\n",
        "    precision_score,\n",
        "    recall_score\n",
        ")\n",
        "\n",
        "model_h = GaussianNB()\n",
        "model_l = GaussianNB()\n",
        "model_m = GaussianNB()\n",
        "\n",
        "model_h_v2 = GaussianNB(var_smoothing = 1e-5)\n",
        "model_l_v2 = GaussianNB(var_smoothing = 1e-5)\n",
        "model_m_v2 = GaussianNB(var_smoothing = 1e-5)\n",
        "\n",
        "model_h_v3 = GaussianNB(var_smoothing = 1e-23)\n",
        "model_l_v3 = GaussianNB(var_smoothing = 1e-23)\n",
        "model_m_v3 = GaussianNB(var_smoothing = 1e-23)\n",
        "\n",
        "model_h.fit(X_train_h, y_train_h);\n",
        "model_l.fit(X_train_l, y_train_l);\n",
        "model_m.fit(X_train_m, y_train_m);\n",
        "\n",
        "model_h_v2.fit(X_train_h, y_train_h);\n",
        "model_l_v2.fit(X_train_l, y_train_l);\n",
        "model_m_v2.fit(X_train_m, y_train_m);\n",
        "\n",
        "model_h_v3.fit(X_train_h, y_train_h);\n",
        "model_l_v3.fit(X_train_l, y_train_l);\n",
        "model_m_v3.fit(X_train_m, y_train_m);\n",
        "\n",
        "y_pred_h_naive = model_h.predict(X_test_h)\n",
        "y_pred_l_naive = model_l.predict(X_test_l)\n",
        "y_pred_m_naive = model_m.predict(X_test_m)\n",
        "\n",
        "y_pred_h_naive_v2 = model_h_v2.predict(X_test_h)\n",
        "y_pred_l_naive_v2 = model_l_v2.predict(X_test_l)\n",
        "y_pred_m_naive_v2 = model_m_v2.predict(X_test_m)\n",
        "\n",
        "y_pred_h_naive_v3 = model_h_v3.predict(X_test_h)\n",
        "y_pred_l_naive_v3 = model_l_v3.predict(X_test_l)\n",
        "y_pred_m_naive_v3 = model_m_v3.predict(X_test_m)"
      ],
      "metadata": {
        "id": "fPzOB-4NBwDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for precision and recall values\n",
        "def print_precision_and_recall(name, test, prediction):\n",
        "  precision = precision_score(test, prediction)\n",
        "  recall = recall_score(test, prediction)\n",
        "  print(f\"{name}: Precision = {precision}, Recall = {recall}\")\n",
        "\n",
        "# precision and recall values for Naive Bayes\n",
        "print_precision_and_recall(\"Naive Bayes with default parameters - High Risk\", y_test_h, y_pred_h_naive)\n",
        "print_precision_and_recall(\"Naive Bayes with default parameters - Low Risk\", y_test_l, y_pred_l_naive)\n",
        "print_precision_and_recall(\"Naive Bayes with default parameters - Medium Risk\", y_test_m, y_pred_m_naive)\n",
        "print(\"\")\n",
        "print_precision_and_recall(\"Naive Bayes with smoothing variable tuned to 1e-3 - High Risk\", y_test_h, y_pred_h_naive_v2)\n",
        "print_precision_and_recall(\"Naive Bayes with smoothing variable tuned to 1e-3 - Low Risk\", y_test_l, y_pred_l_naive_v2)\n",
        "print_precision_and_recall(\"Naive Bayes with smoothing variable tuned to 1e-3 - Medium Risk\", y_test_m, y_pred_m_naive_v2)\n",
        "print(\"\")\n",
        "print_precision_and_recall(\"Naive Bayes with smoothing variable tuned to 1 - High Risk\", y_test_h, y_pred_h_naive_v3)\n",
        "print_precision_and_recall(\"Naive Bayes with smoothing variable tuned to 1 - Low Risk\", y_test_l, y_pred_l_naive_v3)\n",
        "print_precision_and_recall(\"Naive Bayes with smoothing variable tuned to 1 - Medium Risk\", y_test_m, y_pred_m_naive_v3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xDW4C0BviiJ",
        "outputId": "a623657f-0c55-4d77-8abf-e586be8d0e2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes with default parameters - High Risk: Precision = 0.8, Recall = 0.7407407407407407\n",
            "Naive Bayes with default parameters - Low Risk: Precision = 0.6046511627906976, Recall = 0.9397590361445783\n",
            "Naive Bayes with default parameters - Medium Risk: Precision = 0.56, Recall = 0.5753424657534246\n",
            "\n",
            "Naive Bayes with smoothing variable tuned to 1e-3 - High Risk: Precision = 0.8, Recall = 0.7407407407407407\n",
            "Naive Bayes with smoothing variable tuned to 1e-3 - Low Risk: Precision = 0.6046511627906976, Recall = 0.9397590361445783\n",
            "Naive Bayes with smoothing variable tuned to 1e-3 - Medium Risk: Precision = 0.56, Recall = 0.5753424657534246\n",
            "\n",
            "Naive Bayes with smoothing variable tuned to 1 - High Risk: Precision = 0.8, Recall = 0.7407407407407407\n",
            "Naive Bayes with smoothing variable tuned to 1 - Low Risk: Precision = 0.6046511627906976, Recall = 0.9397590361445783\n",
            "Naive Bayes with smoothing variable tuned to 1 - Medium Risk: Precision = 0.56, Recall = 0.5753424657534246\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data analysis using Logistic Regression**"
      ],
      "metadata": {
        "id": "MeIVYNkaLzjQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import the class\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# function for evaluating the model\n",
        "def evaluate_and_print(y_pred, y_test, name, risk_level):\n",
        "    accuracy = accuracy_score(y_pred, y_test)\n",
        "    f1 = f1_score(y_pred, y_test, average=\"weighted\")\n",
        "    print(f\"{name} - Accuracy for predicting {risk_level}:\", accuracy)\n",
        "    print(f\"{name} - F1 Score for {risk_level}:\", f1, \"\\n\")\n",
        "\n",
        "# instantiate the model (using the default parameters)\n",
        "logreg_h = LogisticRegression( max_iter=1000)\n",
        "logreg_l = LogisticRegression( max_iter=1000)\n",
        "logreg_m = LogisticRegression( max_iter=1000)\n",
        "\n",
        "# fit the model with data\n",
        "logreg_h.fit(X_train_h, y_train_h)\n",
        "logreg_l.fit(X_train_l, y_train_l)\n",
        "logreg_m.fit(X_train_m, y_train_m)\n",
        "\n",
        "# predicting the risk levels using the model\n",
        "y_pred_h_log = logreg_h.predict(X_test_h)\n",
        "y_pred_l_log = logreg_l.predict(X_test_l)\n",
        "y_pred_m_log = logreg_m.predict(X_test_m)\n",
        "\n",
        "# For default variation\n",
        "evaluate_and_print(y_pred_h_log, y_test_h, \"Logistic Regression with default parameters\", \"high risk\")\n",
        "evaluate_and_print(y_pred_l_log, y_test_l, \"Logistic Regression with default parameters\", \"low risk\")\n",
        "evaluate_and_print(y_pred_m_log, y_test_m, \"Logistic Regression with default parameters\", \"medium risk\")\n",
        "\n",
        "print_precision_and_recall(\"Logistic Regression with default parameters- High Risk\", y_test_h, y_pred_h_log)\n",
        "print_precision_and_recall(\"Logistic Regression with default parameters - Low Risk\", y_test_l, y_pred_l_log)\n",
        "print_precision_and_recall(\"Logistic Regression with default parameters - Medium Risk\", y_test_m, y_pred_m_log)"
      ],
      "metadata": {
        "id": "zf_MdydWxKCl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f8094fb-a0a9-4843-863d-f8fbc1133e0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression with default parameters - Accuracy for predicting high risk: 0.8522167487684729\n",
            "Logistic Regression with default parameters - F1 Score for high risk: 0.8551049276334852 \n",
            "\n",
            "Logistic Regression with default parameters - Accuracy for predicting low risk: 0.7487684729064039\n",
            "Logistic Regression with default parameters - F1 Score for low risk: 0.7514290477463177 \n",
            "\n",
            "Logistic Regression with default parameters - Accuracy for predicting medium risk: 0.6995073891625616\n",
            "Logistic Regression with default parameters - F1 Score for medium risk: 0.7640821138358085 \n",
            "\n",
            "Logistic Regression with default parameters- High Risk: Precision = 0.75, Recall = 0.6666666666666666\n",
            "Logistic Regression with default parameters - Low Risk: Precision = 0.7162162162162162, Recall = 0.6385542168674698\n",
            "Logistic Regression with default parameters - Medium Risk: Precision = 0.8333333333333334, Recall = 0.2054794520547945\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiating with variation 1 (adjusting regularization strength)\n",
        "logreg_v1_h = LogisticRegression(C=0.5, max_iter=1000)\n",
        "logreg_v1_l = LogisticRegression(C=0.5, max_iter=1000)\n",
        "logreg_v1_m = LogisticRegression(C=0.5, max_iter=1000)\n",
        "\n",
        "logreg_v1_h.fit(X_train_h, y_train_h)\n",
        "logreg_v1_l.fit(X_train_l, y_train_l)\n",
        "logreg_v1_m.fit(X_train_m, y_train_m)\n",
        "\n",
        "y_pred_h_logv1 = logreg_v1_h.predict(X_test_h)\n",
        "y_pred_l_logv1 = logreg_v1_l.predict(X_test_l)\n",
        "y_pred_m_logv1 = logreg_v1_m.predict(X_test_m)\n",
        "\n",
        "# For variation 1\n",
        "evaluate_and_print(y_pred_h_logv1, y_test_h, \"Logistic Regression with changed regularization strength\", \"high risk\")\n",
        "evaluate_and_print(y_pred_l_logv1, y_test_l, \"Logistic Regression with changed regularization strength\", \"low risk\")\n",
        "evaluate_and_print(y_pred_m_logv1, y_test_m, \"Logistic Regression with changed regularization strength\", \"medium risk\")\n",
        "\n",
        "print_precision_and_recall(\"Logistic Regression with changed regularization strength - High Risk\", y_test_h, y_pred_h_log)\n",
        "print_precision_and_recall(\"Logistic Regression with changed regularization strength - Low Risk\", y_test_l, y_pred_l_log)\n",
        "print_precision_and_recall(\"Logistic Regression with changed regularization strength - Medium Risk\", y_test_m, y_pred_m_log)"
      ],
      "metadata": {
        "id": "8QBLkivmDbd_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02f52e9c-90c1-4fa6-c5a3-7e7ee6b421f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression with changed regularization strength - Accuracy for predicting high risk: 0.8522167487684729\n",
            "Logistic Regression with changed regularization strength - F1 Score for high risk: 0.8551049276334852 \n",
            "\n",
            "Logistic Regression with changed regularization strength - Accuracy for predicting low risk: 0.7487684729064039\n",
            "Logistic Regression with changed regularization strength - F1 Score for low risk: 0.7514290477463177 \n",
            "\n",
            "Logistic Regression with changed regularization strength - Accuracy for predicting medium risk: 0.6995073891625616\n",
            "Logistic Regression with changed regularization strength - F1 Score for medium risk: 0.7640821138358085 \n",
            "\n",
            "Logistic Regression with changed regularization strength - High Risk: Precision = 0.75, Recall = 0.6666666666666666\n",
            "Logistic Regression with changed regularization strength - Low Risk: Precision = 0.7162162162162162, Recall = 0.6385542168674698\n",
            "Logistic Regression with changed regularization strength - Medium Risk: Precision = 0.8333333333333334, Recall = 0.2054794520547945\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiating with variation 2 (changing the solver, using Stochastic Average Gradient descent)\n",
        "logreg_v2_h = LogisticRegression(solver='sag', max_iter=1000)\n",
        "logreg_v2_l = LogisticRegression(solver='sag', max_iter=1000)\n",
        "logreg_v2_m = LogisticRegression(solver='sag', max_iter=1000)\n",
        "\n",
        "logreg_v2_h.fit(X_train_h, y_train_h)\n",
        "logreg_v2_l.fit(X_train_l, y_train_l)\n",
        "logreg_v2_m.fit(X_train_m, y_train_m)\n",
        "\n",
        "y_pred_h_logv2 = logreg_v2_h.predict(X_test_h)\n",
        "y_pred_l_logv2 = logreg_v2_l.predict(X_test_l)\n",
        "y_pred_m_logv2 = logreg_v2_m.predict(X_test_m)\n",
        "\n",
        "# For variation 2\n",
        "evaluate_and_print(y_pred_h_logv2, y_test_h, \"Logistic Regression with SAG solver\", \"high risk\")\n",
        "evaluate_and_print(y_pred_l_logv2, y_test_l, \"Logistic Regression with SAG solver\", \"low risk\")\n",
        "evaluate_and_print(y_pred_m_logv2, y_test_m, \"Logistic Regression with SAG solver\", \"medium risk\")\n",
        "\n",
        "print_precision_and_recall(\"Logistic Regression with SAG solver - High Risk\", y_test_h, y_pred_h_log)\n",
        "print_precision_and_recall(\"Logistic Regression with SAG solver - Low Risk\", y_test_l, y_pred_l_log)\n",
        "print_precision_and_recall(\"Logistic Regression with SAG solver - Medium Risk\", y_test_m, y_pred_m_log)"
      ],
      "metadata": {
        "id": "r6-IBKk9DkiN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54287fb1-1485-4359-9c52-48e7a9ebd0e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression with SAG solver - Accuracy for predicting high risk: 0.8719211822660099\n",
            "Logistic Regression with SAG solver - F1 Score for high risk: 0.8774471635150168 \n",
            "\n",
            "Logistic Regression with SAG solver - Accuracy for predicting low risk: 0.7044334975369458\n",
            "Logistic Regression with SAG solver - F1 Score for low risk: 0.707995452823039 \n",
            "\n",
            "Logistic Regression with SAG solver - Accuracy for predicting medium risk: 0.6995073891625616\n",
            "Logistic Regression with SAG solver - F1 Score for medium risk: 0.7640821138358085 \n",
            "\n",
            "Logistic Regression with SAG solver - High Risk: Precision = 0.75, Recall = 0.6666666666666666\n",
            "Logistic Regression with SAG solver - Low Risk: Precision = 0.7162162162162162, Recall = 0.6385542168674698\n",
            "Logistic Regression with SAG solver - Medium Risk: Precision = 0.8333333333333334, Recall = 0.2054794520547945\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Comparison Results**\n",
        "\n",
        "| Model | Type | Precision | Recall |\n",
        "| -------- | ------- | ------- | ------- |\n",
        "|Logistic Regression| Default Parameters (High Risk) | 83.10% | 60.82% |\n",
        "|Logistic Regression| Default Parameters (Low Risk) | 59.70% | 67.80% |\n",
        "|Logistic Regression| Default Parameters (Medium Risk) | 69.05% | 24.17% |\n",
        "|Naive Bayes| Default Parameters (High Risk) | 84.42% | 67.01% |\n",
        "|Naive Bayes| Default Parameters (Low Risk) | 53.21% | 98.31% |\n",
        "|Naive Bayes| Default Parameters (Medium Risk) | 48.85% | 53.33% |"
      ],
      "metadata": {
        "id": "pOwBVv4Cub1I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train/test/evaluate your 2 models in cross-validation**\n"
      ],
      "metadata": {
        "id": "7yM1ULdfYe5k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will now analyze the models with K-Fold cross validation. For supervised learning, it is crucial to separate the provided data into different groups for training and test purposes. If this is not done then there isn't a valid way to test whether the model you trained will be a good predictor on a brand new data. Thus we divide our csv data into 4 different sections, and we will train the model with 3 sections and use the remaining section to test our model and determine its validity"
      ],
      "metadata": {
        "id": "c7zg9R732IAx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import ( KFold )\n",
        "\n",
        "def KFoldResult(n, X, y, model):\n",
        "  kf = KFold(n_splits=4)\n",
        "\n",
        "  fold = 0\n",
        "\n",
        "  acc, pres, rec = 0, 0, 0\n",
        "\n",
        "  for train_idx, val_idx in kf.split(X, y):\n",
        "    X_tr = X.loc[train_idx]\n",
        "    y_tr = y.loc[train_idx]\n",
        "\n",
        "    X_val = X.loc[val_idx]\n",
        "    y_val = y.loc[val_idx]\n",
        "\n",
        "    if model == 'logistic':\n",
        "        model = LogisticRegression(max_iter=1000)\n",
        "    elif model == 'logistic_regularization':\n",
        "        model = LogisticRegression(max_iter=1000, C=0.5)\n",
        "    elif model == 'logistic_solver':\n",
        "        model = LogisticRegression(max_iter=1000, solver='sag')\n",
        "    elif model == 'gaussianDefault':\n",
        "        model = GaussianNB()\n",
        "    elif model == 'gaussianV2':\n",
        "      model = GaussianNB(var_smoothing = 1e-5)\n",
        "    elif model == 'gaussianV3':\n",
        "      model = GaussianNB(var_smoothing = 1e-23)\n",
        "\n",
        "    model.fit(X_tr, y_tr)\n",
        "    pred = model.predict(X_val)\n",
        "\n",
        "    acc_score = accuracy_score(y_val, pred)\n",
        "    acc = acc + acc_score\n",
        "\n",
        "    pres_score = precision_score(y_val, pred)\n",
        "    pres = pres + pres_score\n",
        "\n",
        "    rec_score = recall_score(y_val, pred)\n",
        "    rec = rec + rec_score\n",
        "\n",
        "    print(f\"======= Fold {fold} ========\")\n",
        "    print(\n",
        "        f\"Our accuracy on the validation set is {acc_score:0.4f}, precision is {pres_score:0.4f}, and recall is {rec_score:0.4f}\"\n",
        "    )\n",
        "    fold += 1\n",
        "\n",
        "  print(f\"average accuracy is {acc/fold:0.4f} \\naverage precision is {pres/fold:0.4f} \\naverage recall is {rec/fold:0.4f}\")\n"
      ],
      "metadata": {
        "id": "nwC69EilaeuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('For Naive Bayes with default parameters: \\n')\n",
        "print(\"\\n For High risk \\n\")\n",
        "KFoldResult(4, X, y_h, 'gaussianDefault')\n",
        "\n",
        "print(\"\\n For Mid risk \\n\")\n",
        "KFoldResult(4, X, y_m, 'gaussianDefault')\n",
        "\n",
        "print(\"\\n For Low risk \\n\")\n",
        "KFoldResult(4, X, y_l, 'gaussianDefault')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSqxzEN9eWXN",
        "outputId": "44debec6-8fbc-4af0-f0ef-6ad1d98d7425"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For Naive Bayes with default parameters: \n",
            "\n",
            "\n",
            " For High risk \n",
            "\n",
            "======= Fold 0 ========\n",
            "Our accuracy on the validation set is 0.8465, precision is 0.9107, and recall is 0.6000\n",
            "======= Fold 1 ========\n",
            "Our accuracy on the validation set is 0.8543, precision is 0.7931, and recall is 0.6479\n",
            "======= Fold 2 ========\n",
            "Our accuracy on the validation set is 0.8893, precision is 0.8085, and recall is 0.6667\n",
            "======= Fold 3 ========\n",
            "Our accuracy on the validation set is 0.8735, precision is 0.7547, and recall is 0.6780\n",
            "average accuracy is 0.8659 \n",
            "average precision is 0.8168 \n",
            "average recall is 0.6481\n",
            "\n",
            " For Mid risk \n",
            "\n",
            "======= Fold 0 ========\n",
            "Our accuracy on the validation set is 0.6260, precision is 0.3719, and recall is 0.7031\n",
            "======= Fold 1 ========\n",
            "Our accuracy on the validation set is 0.5906, precision is 0.3130, and recall is 0.5902\n",
            "======= Fold 2 ========\n",
            "Our accuracy on the validation set is 0.6364, precision is 0.5133, and recall is 0.6105\n",
            "======= Fold 3 ========\n",
            "Our accuracy on the validation set is 0.6047, precision is 0.5727, and recall is 0.5431\n",
            "average accuracy is 0.6144 \n",
            "average precision is 0.4427 \n",
            "average recall is 0.6117\n",
            "\n",
            " For Low risk \n",
            "\n",
            "======= Fold 0 ========\n",
            "Our accuracy on the validation set is 0.7402, precision is 0.6309, and recall is 0.8952\n",
            "======= Fold 1 ========\n",
            "Our accuracy on the validation set is 0.7205, precision is 0.6564, and recall is 0.8770\n",
            "======= Fold 2 ========\n",
            "Our accuracy on the validation set is 0.6957, precision is 0.5714, and recall is 0.9505\n",
            "======= Fold 3 ========\n",
            "Our accuracy on the validation set is 0.6008, precision is 0.4258, and recall is 0.8462\n",
            "average accuracy is 0.6893 \n",
            "average precision is 0.5711 \n",
            "average recall is 0.8922\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('For Naive Bayes with smoothing factor of 1e-5: \\n')\n",
        "print(\"\\n For High risk \\n\")\n",
        "KFoldResult(4, X, y_h, 'gaussianV2')\n",
        "\n",
        "print(\"\\n For Mid risk \\n\")\n",
        "KFoldResult(4, X, y_m, 'gaussianV2')\n",
        "\n",
        "print(\"\\n For Low risk \\n\")\n",
        "KFoldResult(4, X, y_l, 'gaussianV2')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7JEnnM85pPI",
        "outputId": "d1dcf643-9b20-4fd0-e4b3-682a17534d17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For Naive Bayes with smoothing factor of 1e-5: \n",
            "\n",
            "\n",
            " For High risk \n",
            "\n",
            "======= Fold 0 ========\n",
            "Our accuracy on the validation set is 0.8465, precision is 0.9107, and recall is 0.6000\n",
            "======= Fold 1 ========\n",
            "Our accuracy on the validation set is 0.8543, precision is 0.7931, and recall is 0.6479\n",
            "======= Fold 2 ========\n",
            "Our accuracy on the validation set is 0.8893, precision is 0.8085, and recall is 0.6667\n",
            "======= Fold 3 ========\n",
            "Our accuracy on the validation set is 0.8735, precision is 0.7547, and recall is 0.6780\n",
            "average accuracy is 0.8659 \n",
            "average precision is 0.8168 \n",
            "average recall is 0.6481\n",
            "\n",
            " For Mid risk \n",
            "\n",
            "======= Fold 0 ========\n",
            "Our accuracy on the validation set is 0.6260, precision is 0.3719, and recall is 0.7031\n",
            "======= Fold 1 ========\n",
            "Our accuracy on the validation set is 0.5906, precision is 0.3130, and recall is 0.5902\n",
            "======= Fold 2 ========\n",
            "Our accuracy on the validation set is 0.6364, precision is 0.5133, and recall is 0.6105\n",
            "======= Fold 3 ========\n",
            "Our accuracy on the validation set is 0.6047, precision is 0.5727, and recall is 0.5431\n",
            "average accuracy is 0.6144 \n",
            "average precision is 0.4427 \n",
            "average recall is 0.6117\n",
            "\n",
            " For Low risk \n",
            "\n",
            "======= Fold 0 ========\n",
            "Our accuracy on the validation set is 0.7402, precision is 0.6309, and recall is 0.8952\n",
            "======= Fold 1 ========\n",
            "Our accuracy on the validation set is 0.7205, precision is 0.6564, and recall is 0.8770\n",
            "======= Fold 2 ========\n",
            "Our accuracy on the validation set is 0.6957, precision is 0.5714, and recall is 0.9505\n",
            "======= Fold 3 ========\n",
            "Our accuracy on the validation set is 0.6047, precision is 0.4295, and recall is 0.8590\n",
            "average accuracy is 0.6903 \n",
            "average precision is 0.5721 \n",
            "average recall is 0.8954\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('For Naive Bayes with smoothing factor of 1e-23: \\n')\n",
        "print(\"\\n For High risk \\n\")\n",
        "KFoldResult(4, X, y_h, 'gaussianV3')\n",
        "\n",
        "print(\"\\n For Mid risk \\n\")\n",
        "KFoldResult(4, X, y_m, 'gaussianV3')\n",
        "\n",
        "print(\"\\n For Low risk \\n\")\n",
        "KFoldResult(4, X, y_l, 'gaussianV3')"
      ],
      "metadata": {
        "id": "jiGJfk1D5yBm",
        "outputId": "a5564271-934b-4dee-97a3-3a5713e845f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For Naive Bayes with smoothing factor of 1e-23: \n",
            "\n",
            "\n",
            " For High risk \n",
            "\n",
            "======= Fold 0 ========\n",
            "Our accuracy on the validation set is 0.8465, precision is 0.9107, and recall is 0.6000\n",
            "======= Fold 1 ========\n",
            "Our accuracy on the validation set is 0.8543, precision is 0.7931, and recall is 0.6479\n",
            "======= Fold 2 ========\n",
            "Our accuracy on the validation set is 0.8893, precision is 0.8085, and recall is 0.6667\n",
            "======= Fold 3 ========\n",
            "Our accuracy on the validation set is 0.8735, precision is 0.7547, and recall is 0.6780\n",
            "average accuracy is 0.8659 \n",
            "average precision is 0.8168 \n",
            "average recall is 0.6481\n",
            "\n",
            " For Mid risk \n",
            "\n",
            "======= Fold 0 ========\n",
            "Our accuracy on the validation set is 0.6260, precision is 0.3719, and recall is 0.7031\n",
            "======= Fold 1 ========\n",
            "Our accuracy on the validation set is 0.5906, precision is 0.3130, and recall is 0.5902\n",
            "======= Fold 2 ========\n",
            "Our accuracy on the validation set is 0.6364, precision is 0.5133, and recall is 0.6105\n",
            "======= Fold 3 ========\n",
            "Our accuracy on the validation set is 0.6047, precision is 0.5727, and recall is 0.5431\n",
            "average accuracy is 0.6144 \n",
            "average precision is 0.4427 \n",
            "average recall is 0.6117\n",
            "\n",
            " For Low risk \n",
            "\n",
            "======= Fold 0 ========\n",
            "Our accuracy on the validation set is 0.7402, precision is 0.6309, and recall is 0.8952\n",
            "======= Fold 1 ========\n",
            "Our accuracy on the validation set is 0.7205, precision is 0.6564, and recall is 0.8770\n",
            "======= Fold 2 ========\n",
            "Our accuracy on the validation set is 0.6957, precision is 0.5714, and recall is 0.9505\n",
            "======= Fold 3 ========\n",
            "Our accuracy on the validation set is 0.6008, precision is 0.4258, and recall is 0.8462\n",
            "average accuracy is 0.6893 \n",
            "average precision is 0.5711 \n",
            "average recall is 0.8922\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('For Logistic Regression with default parameters: \\n')\n",
        "print(\"\\n For High risk \\n\")\n",
        "KFoldResult(4, X, y_h, 'logistic')\n",
        "\n",
        "print(\"\\n For Mid risk \\n\")\n",
        "KFoldResult(4, X, y_m, 'logistic')\n",
        "\n",
        "print(\"\\n For Low risk \\n\")\n",
        "KFoldResult(4, X, y_l, 'logistic')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyYxpKZ36R88",
        "outputId": "7268ff4b-2a24-42c4-af3c-b7178b1e4f4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For Logistic Regression with default parameters: \n",
            "\n",
            "\n",
            " For High risk \n",
            "\n",
            "======= Fold 0 ========\n",
            "Our accuracy on the validation set is 0.8425, precision is 0.9592, and recall is 0.5529\n",
            "======= Fold 1 ========\n",
            "Our accuracy on the validation set is 0.8465, precision is 0.8200, and recall is 0.5775\n",
            "======= Fold 2 ========\n",
            "Our accuracy on the validation set is 0.8419, precision is 0.6491, and recall is 0.6491\n",
            "======= Fold 3 ========\n",
            "Our accuracy on the validation set is 0.8261, precision is 0.6271, and recall is 0.6271\n",
            "average accuracy is 0.8392 \n",
            "average precision is 0.7639 \n",
            "average recall is 0.6017\n",
            "\n",
            " For Mid risk \n",
            "\n",
            "======= Fold 0 ========\n",
            "Our accuracy on the validation set is 0.8031, precision is 0.7500, and recall is 0.3281\n",
            "======= Fold 1 ========\n",
            "Our accuracy on the validation set is 0.7677, precision is 0.5500, and recall is 0.1803\n",
            "======= Fold 2 ========\n",
            "Our accuracy on the validation set is 0.6561, precision is 0.5952, and recall is 0.2632\n",
            "======= Fold 3 ========\n",
            "Our accuracy on the validation set is 0.6087, precision is 0.9048, and recall is 0.1638\n",
            "average accuracy is 0.7089 \n",
            "average precision is 0.7000 \n",
            "average recall is 0.2339\n",
            "\n",
            " For Low risk \n",
            "\n",
            "======= Fold 0 ========\n",
            "Our accuracy on the validation set is 0.8110, precision is 0.7767, and recall is 0.7619\n",
            "======= Fold 1 ========\n",
            "Our accuracy on the validation set is 0.6811, precision is 0.7113, and recall is 0.5656\n",
            "======= Fold 2 ========\n",
            "Our accuracy on the validation set is 0.7154, precision is 0.7101, and recall is 0.4851\n",
            "======= Fold 3 ========\n",
            "Our accuracy on the validation set is 0.6601, precision is 0.4623, and recall is 0.6282\n",
            "average accuracy is 0.7169 \n",
            "average precision is 0.6651 \n",
            "average recall is 0.6102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('For Logistic Regression with regularized strength of 0.5: \\n')\n",
        "print(\"\\n For High risk \\n\")\n",
        "KFoldResult(4, X, y_h, 'logistic_regularization')\n",
        "\n",
        "print(\"\\n For Mid risk \\n\")\n",
        "KFoldResult(4, X, y_m, 'logistic_regularization')\n",
        "\n",
        "print(\"\\n For Low risk \\n\")\n",
        "KFoldResult(4, X, y_l, 'logistic_regularization')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5fux5Q26fJ3",
        "outputId": "485568a8-f569-4b46-8bc2-7093754a1337"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For Logistic Regression with regularized stremgth of 0.5: \n",
            "\n",
            "\n",
            " For High risk \n",
            "\n",
            "======= Fold 0 ========\n",
            "Our accuracy on the validation set is 0.8425, precision is 0.9592, and recall is 0.5529\n",
            "======= Fold 1 ========\n",
            "Our accuracy on the validation set is 0.8465, precision is 0.8200, and recall is 0.5775\n",
            "======= Fold 2 ========\n",
            "Our accuracy on the validation set is 0.8419, precision is 0.6491, and recall is 0.6491\n",
            "======= Fold 3 ========\n",
            "Our accuracy on the validation set is 0.8261, precision is 0.6271, and recall is 0.6271\n",
            "average accuracy is 0.8392 \n",
            "average precision is 0.7639 \n",
            "average recall is 0.6017\n",
            "\n",
            " For Mid risk \n",
            "\n",
            "======= Fold 0 ========\n",
            "Our accuracy on the validation set is 0.8031, precision is 0.7500, and recall is 0.3281\n",
            "======= Fold 1 ========\n",
            "Our accuracy on the validation set is 0.7283, precision is 0.3947, and recall is 0.2459\n",
            "======= Fold 2 ========\n",
            "Our accuracy on the validation set is 0.6561, precision is 0.5952, and recall is 0.2632\n",
            "======= Fold 3 ========\n",
            "Our accuracy on the validation set is 0.5968, precision is 0.7917, and recall is 0.1638\n",
            "average accuracy is 0.6961 \n",
            "average precision is 0.6329 \n",
            "average recall is 0.2502\n",
            "\n",
            " For Low risk \n",
            "\n",
            "======= Fold 0 ========\n",
            "Our accuracy on the validation set is 0.8110, precision is 0.7767, and recall is 0.7619\n",
            "======= Fold 1 ========\n",
            "Our accuracy on the validation set is 0.6811, precision is 0.7113, and recall is 0.5656\n",
            "======= Fold 2 ========\n",
            "Our accuracy on the validation set is 0.7154, precision is 0.7101, and recall is 0.4851\n",
            "======= Fold 3 ========\n",
            "Our accuracy on the validation set is 0.6561, precision is 0.4579, and recall is 0.6282\n",
            "average accuracy is 0.7159 \n",
            "average precision is 0.6640 \n",
            "average recall is 0.6102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('For Logistic Regression with the solver of SAG: \\n')\n",
        "print(\"\\n For High risk \\n\")\n",
        "KFoldResult(4, X, y_h, 'logistic_solver')\n",
        "\n",
        "print(\"\\n For Mid risk \\n\")\n",
        "KFoldResult(4, X, y_m, 'logistic_solver')\n",
        "\n",
        "print(\"\\n For Low risk \\n\")\n",
        "KFoldResult(4, X, y_l, 'logistic_solver')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZc-lglr6teQ",
        "outputId": "259b1a96-77cf-4a0c-fa92-54a9b8e5c340"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For Logistic Regression with the solver of SAG: \n",
            "\n",
            "\n",
            " For High risk \n",
            "\n",
            "======= Fold 0 ========\n",
            "Our accuracy on the validation set is 0.8425, precision is 0.9412, and recall is 0.5647\n",
            "======= Fold 1 ========\n",
            "Our accuracy on the validation set is 0.8425, precision is 0.8298, and recall is 0.5493\n",
            "======= Fold 2 ========\n",
            "Our accuracy on the validation set is 0.8854, precision is 0.8182, and recall is 0.6316\n",
            "======= Fold 3 ========\n",
            "Our accuracy on the validation set is 0.8538, precision is 0.7391, and recall is 0.5763\n",
            "average accuracy is 0.8560 \n",
            "average precision is 0.8321 \n",
            "average recall is 0.5805\n",
            "\n",
            " For Mid risk \n",
            "\n",
            "======= Fold 0 ========\n",
            "Our accuracy on the validation set is 0.7835, precision is 0.7143, and recall is 0.2344\n",
            "======= Fold 1 ========\n",
            "Our accuracy on the validation set is 0.7677, precision is 0.5500, and recall is 0.1803\n",
            "======= Fold 2 ========\n",
            "Our accuracy on the validation set is 0.6561, precision is 0.5952, and recall is 0.2632\n",
            "======= Fold 3 ========\n",
            "Our accuracy on the validation set is 0.6087, precision is 0.9048, and recall is 0.1638\n",
            "average accuracy is 0.7040 \n",
            "average precision is 0.6911 \n",
            "average recall is 0.2104\n",
            "\n",
            " For Low risk \n",
            "\n",
            "======= Fold 0 ========\n",
            "Our accuracy on the validation set is 0.7520, precision is 0.7234, and recall is 0.6476\n",
            "======= Fold 1 ========\n",
            "Our accuracy on the validation set is 0.6181, precision is 0.6506, and recall is 0.4426\n",
            "======= Fold 2 ========\n",
            "Our accuracy on the validation set is 0.6522, precision is 0.5823, and recall is 0.4554\n",
            "======= Fold 3 ========\n",
            "Our accuracy on the validation set is 0.6364, precision is 0.4364, and recall is 0.6154\n",
            "average accuracy is 0.6647 \n",
            "average precision is 0.5982 \n",
            "average recall is 0.5403\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Results Analysis**\n",
        "\n",
        "The evaluation method from the previous section can help us determine the overall performance of our model. We have in total 6 models, 3 models with different training parameters, for both Naive Bayes and logistic regression.\n",
        "\n",
        "*For Naive Bayes*\n",
        "\n",
        "| Risk Level | Smoothing Factor | Average Accuracy | Average Precision | Average Recall |\n",
        "|------------|------------------|------------------|-------------------|---------------|\n",
        "| High Risk  | Default          | 0.8659           | 0.8168            | 0.6481        |\n",
        "| High Risk  | 1e-5             | 0.8392           | 0.7639            | 0.6017        |\n",
        "| High Risk  | 1e-23            | 0.8392           | 0.7639            | 0.6017        |\n",
        "| Mid Risk   | Default          | 0.6144           | 0.4427            | 0.6117        |\n",
        "| Mid Risk   | 1e-5             | 0.6144           | 0.4427            | 0.6117        |\n",
        "| Mid Risk   | 1e-23            | 0.6144           | 0.4427            | 0.6117        |\n",
        "| Low Risk   | Default          | 0.7169           | 0.6651            | 0.6102        |\n",
        "| Low Risk   | 1e-5             | 0.6903           | 0.5721            | 0.8954        |\n",
        "| Low Risk   | 1e-23            | 0.6893           | 0.5711            | 0.8922        |\n",
        "\n",
        "The average accuracy for high risk algorithms is about 0.84, average precision is about 0.77, and average recall is 0.62\n",
        "\n",
        "The average accuracy for mid risk algorithms is about 0.61, average precision is about 0.44, and average recall is 0.61\n",
        "\n",
        "The average accuracy for low risk algorithms is about 0.70, average precision is about 0.60, and average recall is 0.79\n",
        "\n",
        "\\\n",
        "\n",
        "*For logistic regression*\n",
        "\n",
        "| Risk Level | Configuration | Average Accuracy | Average Precision | Average Recall |\n",
        "|-------------|---------------|-------------------|-------------------|----------------|\n",
        "| High Risk  | Default        | 0.8392            | 0.7639            | 0.6017         |\n",
        "| High Risk  |  Strength 0.5   | 0.8392            | 0.7639            | 0.6017         |\n",
        "| High Risk  | Solver SAG     | 0.8560            | 0.8321            | 0.5805         |\n",
        "| Mid Risk   | Default        | 0.7089            | 0.7000            | 0.2339         |\n",
        "| Mid Risk   |  Strength 0.5   | 0.6961            | 0.6329            | 0.2502         |\n",
        "| Mid Risk   |  Solver SAG     | 0.7040            | 0.6911            | 0.2104         |\n",
        "| Low Risk   |  Default        | 0.7169            | 0.6651            | 0.6102         |\n",
        "| Low Risk   |  Strength 0.5   | 0.7159            | 0.6640            | 0.6102         |\n",
        "| Low Risk   |  Solver SAG     | 0.6647            | 0.5982            | 0.5403         |\n",
        "\n",
        "The average accuracy for high risk algorithms is about 0.84, average precision is about 0.78, and average recall is 0.59\n",
        "\n",
        "The average accuracy for mid risk algorithms is about 0.70, average precision is about 0.66, and average recall is 0.23\n",
        "\n",
        "The average accuracy for low risk algorithms is about 0.67, average precision is about 0.63, and average recall is 0.58 \\\n",
        "<br>\n",
        "\n",
        "---\n",
        "Comparing the 2 models, Naive Bayes based algorithm seemed to be performing better when predicting the potential risk intensity level during pregnancy  when given a set of information. However a common theme between the 2 models is that they seem to be able to perform better when it comes to detect high risk levels and not so much for the mid and low levels."
      ],
      "metadata": {
        "id": "WaGm_CVN9FuC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion**\n",
        "\n",
        "This study is aimed to implement various learning algorithm and learn the intricacies and details in the process.The Maternal Health Risk dataset was chosen at random, but it demonstrated a bood balance of data to train on and it is already well-organized so minimal data manipulation is needed. Once the data are primed for analysis, two primary predictive models, Logistic Regression and Gaussian Naive Bayes, are used to train the model, with default configuration and two additional variations. The consistent use of k-fold cross-validation across all models and variations ensured the reliability of our results.\n",
        "\n",
        "The various visualizations and metrics, devoid of any hardcoded values, ensured that our results were both transparent and replicable. This study not only enhanced my understanding of predictive modeling but also underscored the importance of iterative testing and optimization in the field of artificial intelligence. It is evident that with the right combination of data, model choice, and parameter tuning can significantly impact the outcomes, resulting in a more accurate and insightful predictions in real-world scenarios."
      ],
      "metadata": {
        "id": "NUADZywyF5ZG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**References used**\n",
        "* https://www.datacamp.com/tutorial/understanding-logistic-regression-python  \\\n",
        "* https://www.datacamp.com/tutorial/naive-bayes-scikit-learn \\\n",
        "* https://towardsdatascience.com/dont-sweat-the-solver-stuff-aea7cddc3451 \\\n",
        "* https://www.youtube.com/watch?v=-8s9KuNo5SA \\"
      ],
      "metadata": {
        "id": "LPKg95aRMddb"
      }
    }
  ]
}